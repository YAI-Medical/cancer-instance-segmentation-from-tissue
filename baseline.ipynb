{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "baseline.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRDo6N_kc4Gs"
   },
   "source": [
    "# **YAI 2021 Fall Project - Medical Project Team**\n",
    "\n",
    "**Participants**\n",
    "\n",
    "* Dongha Kim - Yonsei Univ. College of Medicine.\n",
    "\n",
    "* Donggeon Bae - Yonsei. Univ. Dept. of Electrical and Electronic Engineering.\n",
    "\n",
    "* Junho Lee - Yonsei Univ. Dept. of Computer Engineering.\n",
    "\n",
    "\n",
    "## Description\n",
    "\n",
    "TBD\n",
    "\n",
    "\n",
    "## Dataset Information\n",
    "\n",
    "**Cancer Instance Segmentation and Classification: kaggle**\n",
    "\n",
    "19 Tissue types (Breast, Colon, Bile-duct, Esophagus, Uterus, Lung, Cervix, Head&Neck, Skin, Adrenal Gland, Kidney, Stomach, Prostate, Testis, Liver, Thyroid, Pancreas, Ovary, Bladder). Note, that it also unifies existing datasets within it, we have carefully labelled these under a single nuclei categories schema that is common to all 19 tissues.\n",
    "\n",
    "* https://www.kaggle.com/andrewmvd/cancer-inst-segmentation-and-classification\n",
    "\n",
    "* https://www.kaggle.com/andrewmvd/cancer-instance-segmentation-and-classification-2\n",
    "\n",
    "* https://www.kaggle.com/andrewmvd/cancer-instance-segmentation-and-classification-3\n",
    "\n",
    "\n",
    "## Model Architecture\n",
    "\n",
    "**Baseline: DeepLabV3 + Resnet101**\n",
    "\n",
    "* https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/\n",
    "\n",
    "\n",
    "## Full Source Code\n",
    "\n",
    "* github link: TBD\n",
    "\n",
    "All non-necessary codes are modularized as package. Watch all codes in github repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGbSgpiN8IUx"
   },
   "source": [
    "# Runtime Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJ33LXbm80XB"
   },
   "source": [
    "## Mount Data Drive"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KcV-0Ch3X7KR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632134076906,
     "user_tz": -540,
     "elapsed": 20796,
     "user": {
      "displayName": "Donggeon Bae",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjwo7aG7d0_V_a3OEHiuPAww1GZQ9sADWLlvLwp4A=s64",
      "userId": "16696796393874585002"
     }
    },
    "outputId": "44482f69-ff27-47fd-91f3-6a10dc190567"
   },
   "source": [
    "try:\n",
    "    from google.colab import drive  # NOQA\n",
    "except ImportError:\n",
    "    raise RuntimeError(\"This notebook must be run on colab runtime!\")\n",
    "else:\n",
    "    drive.mount('/content/drive')  # NOQA\n",
    "    %cd \"/content/drive/Shareddrives/YAI 2021 가을학기 의료 프로젝트팀\""
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "4/1AX4XfWiCLUxk0W6otTsQUVHKixUYmxr9ZxN0Ns8CDye3653gHvp2_ukhkyA\n",
      "Mounted at /content/drive\n",
      "/content/drive/Shareddrives/YAI 2021 가을학기 의료 프로젝트팀\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfXMD_Go811J"
   },
   "source": [
    "## View Runtime Information"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "KheBmjwOX7KU"
   },
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0 or gpu_info.find('not found') >= 0:\n",
    "    import os\n",
    "    if 'TPU_NAME' in os.environ:\n",
    "        mode = 'xla'\n",
    "        print('TPU Runtime')\n",
    "    else:\n",
    "        mode = 'cpu'\n",
    "        print('Not connected to a GPU')\n",
    "else:\n",
    "    mode = 'cuda'\n",
    "    print(gpu_info)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vNp2idKuX7KU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631445082616,
     "user_tz": -540,
     "elapsed": 12,
     "user": {
      "displayName": "Dong Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi0xVQjwNKm6at9ATEQ2-UDaAG_npfBWPFaYGHauA=s64",
      "userId": "15764707910563300297"
     }
    },
    "outputId": "d324cb91-eb7a-4f1f-c3a4-1da4f87d877e"
   },
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print(f'Your runtime has {ram_gb:.1f} gigabytes of available RAM\\n'\n",
    "      f'{\"Not\" if ram_gb < 20 else \"You are\"} using a high-RAM runtime!')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Your runtime has 27.3 gigabytes of available RAM\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ay84MChOX7KV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631445082616,
     "user_tz": -540,
     "elapsed": 7,
     "user": {
      "displayName": "Dong Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi0xVQjwNKm6at9ATEQ2-UDaAG_npfBWPFaYGHauA=s64",
      "userId": "15764707910563300297"
     }
    },
    "outputId": "7f22d4c2-d869-404c-dcf4-03e1e762d851"
   },
   "source": [
    "import sys\n",
    "import platform\n",
    "print(f\"OS version: \\t\\t{platform.platform()}\\nPython version:\\t\\t{sys.version.replace(chr(10), str())}\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "OS version: \t\tLinux-5.4.104+-x86_64-with-Ubuntu-18.04-bionic\n",
      "Python version:\t\t3.7.11 (default, Jul  3 2021, 18:01:19) [GCC 7.5.0]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_Mk456L84uM"
   },
   "source": [
    "## Prepare device and library"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUpSXOC4X7KV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631445085326,
     "user_tz": -540,
     "elapsed": 2713,
     "user": {
      "displayName": "Dong Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi0xVQjwNKm6at9ATEQ2-UDaAG_npfBWPFaYGHauA=s64",
      "userId": "15764707910563300297"
     }
    },
    "outputId": "4b720a7b-5748-430c-d027-6545756a5ec5"
   },
   "source": [
    "# Prepare device\n",
    "\n",
    "if mode == 'xla':\n",
    "    try:\n",
    "        import torch_xla\n",
    "    except ImportError:\n",
    "        !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "        !python pytorch-xla-env-setup.py\n",
    "        !rm -rf pytorch-xla-env-setup.py *.whl\n",
    "        import torch_xla\n",
    "    import torch\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    # Acquires the default Cloud TPU core and moves the model to it\n",
    "    device = xm.xla_device()\n",
    "\n",
    "elif mode == 'cuda':\n",
    "    import torch\n",
    "    device = torch.device(\"cuda\")\n",
    "    # loader_kwargs = dict(pin_memory=True)\n",
    "\n",
    "else:\n",
    "    import torch\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Torch version:\\t\\t{torch.__version__}\\nTorch device:\\t\\t{device}\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Torch version:\t\t1.9.0+cu102\n",
      "Torch device:\t\tcuda\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ToM22BPPX7KW",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631445088731,
     "user_tz": -540,
     "elapsed": 3408,
     "user": {
      "displayName": "Dong Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi0xVQjwNKm6at9ATEQ2-UDaAG_npfBWPFaYGHauA=s64",
      "userId": "15764707910563300297"
     }
    },
    "outputId": "ca47e46a-7ce1-4526-f783-4b8da0acf264"
   },
   "source": [
    "# After all installation, import all libraries used.\n",
    "\n",
    "!pip install torchinfo\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import IterableDataset, ChainDataset, RandomSampler, DataLoader\n",
    "from torchvision.datasets import VisionDataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "from torchvision.models.segmentation.fcn import FCNHead\n",
    "from torchvision.models.segmentation import deeplabv3_resnet101\n",
    "import torchinfo\n",
    "from tqdm.notebook import tqdm\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch.transforms import ToTensorV2\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.5.3-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.5.3\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BqF5c868v_d"
   },
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "QnZP1IslX7KW"
   },
   "source": [
    "**Dataset Information**\n",
    "\n",
    "\n",
    "19 Tissue types (Breast, Colon, Bile-duct, Esophagus, Uterus, Lung, Cervix, Head&Neck, Skin, Adrenal Gland, Kidney, Stomach, Prostate, Testis, Liver, Thyroid, Pancreas, Ovary, Bladder). Note, that it also unifies existing datasets within it, we have carefully labelled these under a single nuclei categories schema that is common to all 19 tissues.\n",
    "\n",
    "**This particular directory includes training patches of size 256x256 and their masks, this is one of the folds. In total there are more than 7 thousand training patches within all of the three folds.**\n",
    "\n",
    "The files within each fold directories are:\n",
    "\n",
    "* `images.npy` - image patches of 256x256\n",
    "\n",
    "* `masks.npy` an array of 6 channel instance-wise masks (0: Neoplastic cells, 1: Inflammatory, 2: Connective/Soft tissue cells, 3: Dead Cells, 4: Epithelial, 6: Background)\n",
    "\n",
    "* `types.py`  tissue type that a given path was extracted from.\n",
    "\n",
    "**The `masks/` directory and it's contents are licensed under a Creative Commons [Attribution-NonCommercial-ShareAlike 4.0 International](http://creativecommons.org/licenses/by-nc-sa/4.0/)  license**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_J121a_8OAp"
   },
   "source": [
    "## Make Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "SFuu5Jq7X7KY"
   },
   "source": [
    "class NumpyDataset(VisionDataset):  # 메모리 충분하신 분만 쓰세요\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            image_path,\n",
    "            mask_path,\n",
    "            type_path=None,\n",
    "            transform=ToTensor(),\n",
    "            target_transform=ToTensor(),\n",
    "    ):\n",
    "        VisionDataset.__init__(\n",
    "            self,\n",
    "            root=None,  # type: ignore\n",
    "            transforms=None,\n",
    "            transform=transform,\n",
    "            target_transform=target_transform,\n",
    "        )\n",
    "\n",
    "        self.image_array = np.load(image_path)\n",
    "        self.mask_array = np.load(mask_path)\n",
    "        assert self.image_array.shape[0] == self.mask_array.shape[0]\n",
    "        if type_path is not None:\n",
    "            self.type_array = np.load(type_path)\n",
    "            assert self.image_array.shape[0] == self.type_array.shape[0]\n",
    "        else:\n",
    "            self.type_array = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image_array.shape[0]\n",
    "\n",
    "    def __iter__(self):\n",
    "        for index in range(len(self)):\n",
    "            image, mask = self.image_array[index], self.mask_array[index]\n",
    "            if self.transform is not None:\n",
    "                image = self.transform(image)\n",
    "            if self.target_transform is not None:\n",
    "                mask = self.target_transform(mask)\n",
    "            yield image, mask\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, mask = self.image_array[index], self.mask_array[index]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform is not None:\n",
    "            mask = self.target_transform(mask)\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "class LazyEvalNumpyDataset(IterableDataset, NumpyDataset):\n",
    "\n",
    "    __length_cache = None\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            image_path,\n",
    "            mask_path,\n",
    "            type_path=None,\n",
    "            transform=ToTensor(),\n",
    "            target_transform=ToTensor(),\n",
    "            sampler_class=None,\n",
    "            sampler_kwargs=None,\n",
    "            length=None,\n",
    "    ):\n",
    "        VisionDataset.__init__(\n",
    "            self,\n",
    "            root=None,  # type: ignore\n",
    "            transforms=None,\n",
    "            transform=transform,\n",
    "            target_transform=target_transform,\n",
    "        )\n",
    "\n",
    "        self.image_path = image_path\n",
    "        assert os.path.isfile(image_path)\n",
    "        self.mask_path = mask_path\n",
    "        assert os.path.isfile(mask_path)\n",
    "        self.type_path = type_path\n",
    "        assert type_path is None or os.path.isfile(type_path)\n",
    "        if length is not None:\n",
    "            self.__length_cache = length\n",
    "\n",
    "        if sampler_class is not None:\n",
    "            self.sampler = sampler_class(self, **(sampler_kwargs or {}))\n",
    "        else:\n",
    "            self.sampler = None\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.__length_cache is None:\n",
    "            self.__length_cache = np.load(self.image_path).shape[0]\n",
    "        return self.__length_cache\n",
    "\n",
    "    def __iter__(self):\n",
    "        image_array = np.load(self.image_path)\n",
    "        mask_array = np.load(self.mask_path)\n",
    "        if self.__length_cache is None:\n",
    "            self.__length_cache = image_array.shape[0]\n",
    "        sampler = self.sampler or range(len(image_array))\n",
    "        for index in sampler:\n",
    "            image, mask = image_array[index], mask_array[index]\n",
    "            if self.transform is not None:\n",
    "                image = self.transform(image)\n",
    "            if self.target_transform is not None:\n",
    "                mask = self.target_transform(mask)\n",
    "            yield image, mask\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        raise NotImplementedError\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ytwG0pR8R_f"
   },
   "source": [
    "## Instantiate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "1ph496K4X7KY"
   },
   "source": [
    "batch_length = [886, 885, 885, 841, 841, 841, 908, 907, 907]\n",
    "\n",
    "train_subset = [0, 2, 3, 4, 6, 8]\n",
    "val_subset = [1, 5]\n",
    "test_subset = [7]\n",
    "\n",
    "path_format = os.path.join(\"data\", \"processed\", \"{0}\", \"{1}.npy\")\n",
    "train_dataset = ChainDataset([\n",
    "    LazyEvalNumpyDataset(\n",
    "        image_path=path_format.format(\"images\", i),\n",
    "        mask_path=path_format.format(\"masks\", i),\n",
    "        length=batch_length[i],\n",
    "        sampler_class=RandomSampler,  # issue\n",
    "    ) for i in train_subset\n",
    "])\n",
    "val_dataset = ChainDataset([\n",
    "    LazyEvalNumpyDataset(\n",
    "        image_path=path_format.format(\"images\", i),\n",
    "        mask_path=path_format.format(\"masks\", i),\n",
    "        length=batch_length[i],\n",
    "    ) for i in val_subset\n",
    "])\n",
    "test_dataset = ChainDataset([\n",
    "    LazyEvalNumpyDataset(\n",
    "        image_path=path_format.format(\"images\", i),\n",
    "        mask_path=path_format.format(\"masks\", i),\n",
    "        length=batch_length[i],\n",
    "    ) for i in test_subset\n",
    "])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rS3Z95DY7c7X"
   },
   "source": [
    "# Network Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvqwNmmM8g5w"
   },
   "source": [
    "## Segmentation Network\n",
    "\n",
    "**Baseline Model**: DeepLabV3-Resnet101\n",
    "\n",
    "Other Architectures\n",
    "\n",
    "* A-HRNet: https://ieeexplore.ieee.org/document/9253142\n",
    "* See Also: https://arxiv.org/pdf/2005.10821.pdf"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VAdd4LSkX7Ka",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631445101357,
     "user_tz": -540,
     "elapsed": 12015,
     "user": {
      "displayName": "Dong Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi0xVQjwNKm6at9ATEQ2-UDaAG_npfBWPFaYGHauA=s64",
      "userId": "15764707910563300297"
     }
    },
    "outputId": "684e2622-0087-4a89-902e-5ccde017fa02"
   },
   "source": [
    "# # Pretrained Model\n",
    "net = deeplabv3_resnet101(pretrained=True, progress=False)\n",
    "net.classifier = DeepLabHead(2048, 6)\n",
    "# net.aux_classifier = nn.Sequential()\n",
    "net.aux_classifier = FCNHead(1024, 6)\n",
    "# # Non-pretrained Model\n",
    "# net = deeplabv3_resnet101(pretrained=False, num_classes=6)\n",
    "\n",
    "trainable_backbone_layers = ['layer4']\n",
    "for n, p in net.named_parameters():\n",
    "    if n.startswith('backbone') and n.split('.')[1] not in trainable_backbone_layers:\n",
    "        p.requires_grad = False\n",
    "\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "if NUM_GPUS > 1:\n",
    "    net = torch.nn.DataParallel(net)\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "torchinfo.summary(net, (1, 3, 256, 256))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet101_coco-586e9e4e.pth\" to /root/.cache/torch/hub/checkpoints/deeplabv3_resnet101_coco-586e9e4e.pth\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "DeepLabV3                                          --                        --\n",
       "├─DeepLabHead: 1                                   --                        --\n",
       "│    └─ASPP: 2                                     --                        --\n",
       "│    │    └─ModuleList: 3-1                        --                        15,206,912\n",
       "├─IntermediateLayerGetter: 1-1                     [1, 2048, 32, 32]         --\n",
       "│    └─Conv2d: 2-1                                 [1, 64, 128, 128]         9,408\n",
       "│    └─BatchNorm2d: 2-2                            [1, 64, 128, 128]         128\n",
       "│    └─ReLU: 2-3                                   [1, 64, 128, 128]         --\n",
       "│    └─MaxPool2d: 2-4                              [1, 64, 64, 64]           --\n",
       "│    └─Sequential: 2-5                             [1, 256, 64, 64]          --\n",
       "│    │    └─Bottleneck: 3-2                        [1, 256, 64, 64]          75,008\n",
       "│    │    └─Bottleneck: 3-3                        [1, 256, 64, 64]          70,400\n",
       "│    │    └─Bottleneck: 3-4                        [1, 256, 64, 64]          70,400\n",
       "│    └─Sequential: 2-6                             [1, 512, 32, 32]          --\n",
       "│    │    └─Bottleneck: 3-5                        [1, 512, 32, 32]          379,392\n",
       "│    │    └─Bottleneck: 3-6                        [1, 512, 32, 32]          280,064\n",
       "│    │    └─Bottleneck: 3-7                        [1, 512, 32, 32]          280,064\n",
       "│    │    └─Bottleneck: 3-8                        [1, 512, 32, 32]          280,064\n",
       "│    └─Sequential: 2-7                             [1, 1024, 32, 32]         --\n",
       "│    │    └─Bottleneck: 3-9                        [1, 1024, 32, 32]         1,512,448\n",
       "│    │    └─Bottleneck: 3-10                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-11                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-12                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-13                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-14                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-15                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-16                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-17                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-18                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-19                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-20                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-21                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-22                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-23                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-24                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-25                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-26                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-27                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-28                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-29                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-30                       [1, 1024, 32, 32]         1,117,184\n",
       "│    │    └─Bottleneck: 3-31                       [1, 1024, 32, 32]         1,117,184\n",
       "│    └─Sequential: 2-8                             [1, 2048, 32, 32]         --\n",
       "│    │    └─Bottleneck: 3-32                       [1, 2048, 32, 32]         6,039,552\n",
       "│    │    └─Bottleneck: 3-33                       [1, 2048, 32, 32]         4,462,592\n",
       "│    │    └─Bottleneck: 3-34                       [1, 2048, 32, 32]         4,462,592\n",
       "├─DeepLabHead: 1-2                                 [1, 6, 32, 32]            --\n",
       "│    └─ASPP: 2-9                                   [1, 256, 32, 32]          --\n",
       "│    │    └─Sequential: 3-35                       [1, 256, 32, 32]          328,192\n",
       "│    └─Conv2d: 2-10                                [1, 256, 32, 32]          589,824\n",
       "│    └─BatchNorm2d: 2-11                           [1, 256, 32, 32]          512\n",
       "│    └─ReLU: 2-12                                  [1, 256, 32, 32]          --\n",
       "│    └─Conv2d: 2-13                                [1, 6, 32, 32]            1,542\n",
       "├─FCNHead: 1-3                                     [1, 6, 32, 32]            --\n",
       "│    └─Conv2d: 2-14                                [1, 256, 32, 32]          2,359,296\n",
       "│    └─BatchNorm2d: 2-15                           [1, 256, 32, 32]          512\n",
       "│    └─ReLU: 2-16                                  [1, 256, 32, 32]          --\n",
       "│    └─Dropout: 2-17                               [1, 256, 32, 32]          --\n",
       "│    └─Conv2d: 2-18                                [1, 6, 32, 32]            1,542\n",
       "====================================================================================================\n",
       "Total params: 60,988,492\n",
       "Trainable params: 60,988,492\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 62.70\n",
       "====================================================================================================\n",
       "Input size (MB): 0.79\n",
       "Forward/backward pass size (MB): 983.67\n",
       "Params size (MB): 243.95\n",
       "Estimated Total Size (MB): 1228.41\n",
       "===================================================================================================="
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fA09nxp8j7l"
   },
   "source": [
    "## Loss Network\n",
    "\n",
    "* More Multi-Label Segmentation Losses: https://jeune-research.tistory.com/entry/Loss-Functions-for-Image-Segmentation-Region-Based-Losses\n",
    "\n",
    "* See also: https://smp.readthedocs.io/en/latest/losses.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "vUerR0qeX7KZ"
   },
   "source": [
    "class DiceLoss(torch.nn.Module):  # Multi label segmentation loss\n",
    "\n",
    "    epsilon = 1e-7\n",
    "\n",
    "    def forward(self, logit, target):\n",
    "        pred = logit.softmax(dim=-3)\n",
    "        intersection = (pred * target).sum(dim=(-1, -2)) + self.epsilon\n",
    "        union = (pred + target).sum(dim=(-1, -2)) + self.epsilon * 2\n",
    "        loss = 1 - (2.0 * intersection / union)\n",
    "        return loss.mean()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQbQBuKM8nDG"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_B_XswG9CDO"
   },
   "source": [
    "## Define Trainer Function"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "MsfvEw7ZX7KZ"
   },
   "source": [
    "def train_one_epoch(model, criterion, optimizer, scheduler, train_loader, val_loader, device, epoch):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    if epoch == 0:  # warm_up_scheduler\n",
    "        warmup_factor = 1. / 1000\n",
    "        warmup_iters = min(1000, len(train_loader) - 1)\n",
    "\n",
    "        def f(x):\n",
    "            if x >= warmup_iters:\n",
    "                return 1\n",
    "            alpha = float(x) / warmup_iters\n",
    "            return warmup_factor * (1 - alpha) + alpha\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, f)\n",
    "\n",
    "    loss_f = None\n",
    "    inner_tq = tqdm(train_loader, total=len(train_loader), leave=False, desc=f'Iteration {epoch} train')\n",
    "\n",
    "    for images, masks in inner_tq:\n",
    "\n",
    "        images = images.to(device).float()\n",
    "        masks = masks.clamp(0., 1.).to(device).float()  # IMPORTANT: clamp\n",
    "\n",
    "        prediction = model(images)\n",
    "        # prediction = prediction.softmax(dim=-3)\n",
    "        loss = criterion(prediction, masks)\n",
    "        loss.backward()\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            loss = loss.mean()  # mean() to average on multi-gpu.\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if epoch == 0:\n",
    "            scheduler.step()\n",
    "\n",
    "        if loss_f is not None:\n",
    "            loss_f = 0.98 * loss_f + 0.02 * loss.item()\n",
    "        else:\n",
    "            loss_f = loss.item()\n",
    "        inner_tq.set_postfix(loss=loss_f)\n",
    "\n",
    "    if epoch != 0 and scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"\\rIteration {epoch} train loss: {loss_f:.4f}\")\n",
    "\n",
    "    if val_loader is not None:\n",
    "        model.eval()\n",
    "        inner_tq = tqdm(val_loader, total=len(val_loader), leave=False, desc=f'Iteration {epoch} eval')\n",
    "        with torch.no_grad():\n",
    "            loss_f = count = 0\n",
    "            for images, masks in inner_tq:\n",
    "                images = images.to(device).float()\n",
    "                masks = masks.clamp(0., 1.).to(device).float()  # IMPORTANT: clamp\n",
    "                prediction = model(images)\n",
    "                loss_f += criterion(prediction, masks).item()\n",
    "                count += 1\n",
    "            loss_f = loss_f / count if count else None\n",
    "            inner_tq.set_postfix(loss=loss_f)\n",
    "            print(f\"Iteration {epoch} eval loss: {loss_f:.4f}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUENX6Cp9Gm3"
   },
   "source": [
    "## Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "64W1o8OeX7Ka"
   },
   "source": [
    "# Lazy-eval iterable dataset: do not set sampler or shuffle options\n",
    "num_epoch = 10\n",
    "\n",
    "batch_size = 100\n",
    "num_workers = 1\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, num_workers=num_workers, drop_last=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size, num_workers=num_workers, drop_last=False)\n",
    "\n",
    "loss_func = DiceLoss()\n",
    "optimizer = optim.SGD(\n",
    "    [p for p in net.parameters() if p.requires_grad],\n",
    "    lr=1e-3, momentum=0.9, weight_decay=0.0005\n",
    ")\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "\n",
    "def load_state_dict(d):\n",
    "    net.load_state_dict(d['model'])\n",
    "    optimizer.load_state_dict(d['optimizer'])\n",
    "    lr_scheduler.load_state_dict(d['lr_scheduler'])\n",
    "\n",
    "\n",
    "def state_dict():\n",
    "    from collections import OrderedDict\n",
    "    d = OrderedDict()\n",
    "    d['model'] = net.state_dict()\n",
    "    d['optimizer'] = optimizer.state_dict()\n",
    "    d['lr_scheduler'] = lr_scheduler.state_dict()\n",
    "    return d\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "0LHQxKvtX7Ka"
   },
   "source": [
    "os.makedirs('checkpoint', exist_ok=True)\n",
    "for ep in range(num_epoch):\n",
    "    train_one_epoch(net, loss_func, optimizer, lr_scheduler, train_loader, val_loader, device, ep)\n",
    "    torch.save(net.state_dict(), os.path.join('checkpoint', 'baseline_epoch{}.pt').format(ep))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xUJ4lidKwxM"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "YLhe0YAfX7Kb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631445101358,
     "user_tz": -540,
     "elapsed": 13,
     "user": {
      "displayName": "Dong Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi0xVQjwNKm6at9ATEQ2-UDaAG_npfBWPFaYGHauA=s64",
      "userId": "15764707910563300297"
     }
    },
    "outputId": "c6bc26ee-2c29-4d51-898a-6a36d3ef7242"
   },
   "source": [
    "net.eval()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeepLabV3(\n",
       "  (backbone): IntermediateLayerGetter(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): DeepLabHead(\n",
       "    (0): ASPP(\n",
       "      (convs): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (3): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (4): ASPPPooling(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux_classifier): FCNHead(\n",
       "    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o4WV7XEPQJX6"
   },
   "source": [
    "torch.save(state_dict(), 'baseline_final.pth')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jsFnwe3cLiky"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}